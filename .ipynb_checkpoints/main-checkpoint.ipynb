{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174abf56-6c86-409e-ab1a-b3295065230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile, File\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d818aaf8-30f7-498f-8424-2c36e16e5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "# Enable CORS for local testing\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8352ab5-bcda-4459-a58f-f74b2d18c6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Brain Loaded Successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "TIMEZONE = 'Asia/Kuala_Lumpur'\n",
    "\n",
    "# Load Artifacts (Ensure these exist in the same folder)\n",
    "try:\n",
    "    model = joblib.load('tiktok_voting_model.pkl')\n",
    "    scaler = joblib.load('tiktok_scaler.pkl')\n",
    "    ROBUST_THRESHOLD = joblib.load('robust_threshold.pkl')\n",
    "    DECISION_THRESHOLD = joblib.load('decision_threshold.pkl')\n",
    "    print(\"AI Brain Loaded Successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Model files not found. Prediction will be disabled. Error: {e}\")\n",
    "    model = None\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def read_root():\n",
    "    # Reads the frontend file\n",
    "    try:\n",
    "        with open(\"index.html\", \"r\") as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"<h1>Error: index.html not found.</h1>\"\n",
    "\n",
    "@app.post(\"/analyze\")\n",
    "async def analyze_file(file: UploadFile = File(...)):\n",
    "    # 1. READ FILE\n",
    "    content = await file.read()\n",
    "    content_str = content.decode('utf-8')\n",
    "    \n",
    "    # 2. PARSE DATA (Robust Pipeline)\n",
    "    matches = re.findall(r\"Date:\\s*(\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2})\\s*UTC\", content_str)\n",
    "    if not matches:\n",
    "        return {\"error\": \"Invalid file format. No dates found.\"}\n",
    "        \n",
    "    df = pd.DataFrame(matches, columns=['timestamp'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['local_time'] = df['timestamp'].dt.tz_localize('UTC').dt.tz_convert(TIMEZONE)\n",
    "    df = df.sort_values('local_time').reset_index(drop=True)\n",
    "    \n",
    "    # 3. CALCULATE METRICS\n",
    "    df['date'] = df['local_time'].dt.date\n",
    "    df['hour'] = df['local_time'].dt.hour\n",
    "    df['is_weekend'] = df['local_time'].dt.dayofweek >= 5\n",
    "    \n",
    "    # Sabotage Logic\n",
    "    df['is_sleep_sabotage'] = df['hour'].isin([2, 3, 4, 5, 6, 7])\n",
    "    df['is_work_sabotage'] = (~df['is_weekend']) & (df['hour'].between(9, 18))\n",
    "    df['is_morning_trigger'] = df['hour'].isin([7, 8, 9, 10])\n",
    "\n",
    "    # Aggregation\n",
    "    daily = df.groupby('date').agg(\n",
    "        total_clicks=('timestamp', 'count'),\n",
    "        late_night_clicks=('is_sleep_sabotage', 'sum'),\n",
    "        work_hour_clicks=('is_work_sabotage', 'sum'),\n",
    "        morning_clicks=('is_morning_trigger', 'sum')\n",
    "    ).reset_index()\n",
    "    daily['day_of_week'] = pd.to_datetime(daily['date']).dt.dayofweek\n",
    "    \n",
    "    # Robust Score Calculation\n",
    "    def calculate_score(row):\n",
    "        sleep_pen = row['late_night_clicks'] * 3.0\n",
    "        if row['day_of_week'] >= 5: # Weekend\n",
    "            return sleep_pen + (row['total_clicks'] * 0.2) \n",
    "        else: # Weekday\n",
    "            return sleep_pen + (row['work_hour_clicks'] * 2.0) + (row['total_clicks'] * 0.05)\n",
    "\n",
    "    daily['raw_score'] = daily.apply(calculate_score, axis=1)\n",
    "    \n",
    "    # Smoothing & Thresholding\n",
    "    cap_value = daily['raw_score'].quantile(0.95)\n",
    "    daily['capped_score'] = np.where(daily['raw_score'] > cap_value, cap_value, daily['raw_score'])\n",
    "    daily['smoothed_score'] = daily['capped_score'].ewm(span=3).mean()\n",
    "    \n",
    "    # Identify Bad Habits (Historical)\n",
    "    daily['is_bad_habit'] = (daily['smoothed_score'] >= ROBUST_THRESHOLD).astype(int)\n",
    "    \n",
    "    # --- 4. PREPARE AI PREDICTION FOR \"TOMORROW\" ---\n",
    "    # We take the LAST day's data to predict the NEXT day's risk\n",
    "    last_day = daily.iloc[-1]\n",
    "    \n",
    "    # Features needed: ['day_of_week', 'prev_score', 'morning_clicks', 'volatility']\n",
    "    # We predict for \"Tomorrow\"\n",
    "    next_day_dow = (last_day['day_of_week'] + 1) % 7\n",
    "    prev_score = last_day['smoothed_score'] # Today's score becomes tomorrow's \"previous\"\n",
    "    # We assume 0 morning clicks for tomorrow (as it hasn't happened) \n",
    "    # OR we use average morning clicks to simulate \"typical behavior\"\n",
    "    avg_morning = daily['morning_clicks'].mean()\n",
    "    volatility = daily['smoothed_score'].rolling(window=5).std().iloc[-1]\n",
    "    if pd.isna(volatility): volatility = 0\n",
    "    \n",
    "    prediction_result = \"AI Model Not Loaded\"\n",
    "    confidence = 0\n",
    "    \n",
    "    if model:\n",
    "        # Create input vector\n",
    "        input_data = pd.DataFrame([[next_day_dow, prev_score, avg_morning, volatility]], \n",
    "                                  columns=['day_of_week', 'prev_score', 'morning_clicks', 'volatility'])\n",
    "        \n",
    "        # Scale\n",
    "        input_scaled = scaler.transform(input_data)\n",
    "        \n",
    "        # Predict\n",
    "        prob = model.predict_proba(input_scaled)[0][1]\n",
    "        confidence = round(prob * 100, 1)\n",
    "        \n",
    "        if prob >= DECISION_THRESHOLD:\n",
    "            prediction_result = \"HIGH RISK OF RELAPSE\"\n",
    "        else:\n",
    "            prediction_result = \"STABLE / LOW RISK\"\n",
    "\n",
    "    # --- 5. PREPARE JSON RESPONSE ---\n",
    "    bad_days_count = int(daily['is_bad_habit'].sum())\n",
    "    total_days = len(daily)\n",
    "    \n",
    "    # Heatmap Data\n",
    "    heatmap_data = df.groupby(['hour', 'day_of_week']).size().reset_index(name='count')\n",
    "    # Convert day_of_week number to name\n",
    "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    heatmap_data['day_name'] = heatmap_data['day_of_week'].apply(lambda x: days[x])\n",
    "    \n",
    "    return {\n",
    "        \"summary\": {\n",
    "            \"total_days\": total_days,\n",
    "            \"bad_days\": bad_days_count,\n",
    "            \"bad_ratio\": round((bad_days_count / total_days) * 100, 1),\n",
    "            \"status\": \"CRITICAL\" if (bad_days_count / total_days) > 0.3 else \"HEALTHY\"\n",
    "        },\n",
    "        \"forecast\": {\n",
    "            \"next_day_risk\": prediction_result,\n",
    "            \"confidence\": confidence,\n",
    "            \"threshold_used\": f\"{DECISION_THRESHOLD:.2f}\"\n",
    "        },\n",
    "        \"charts\": {\n",
    "            \"daily_scores\": daily['smoothed_score'].tolist(),\n",
    "            \"dates\": daily['date'].astype(str).tolist(),\n",
    "            \"threshold\": ROBUST_THRESHOLD,\n",
    "            \"heatmap\": heatmap_data.to_dict(orient='records')\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167f99b4-4e9c-4229-9b42-c19448f84425",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01muvicorn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Run server\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43muvicorn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m0.0.0.0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\uvicorn\\main.py:593\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, timeout_worker_healthcheck, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[39m\n\u001b[32m    591\u001b[39m         Multiprocess(config, target=server.run, sockets=[sock]).run()\n\u001b[32m    592\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m         \u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m    595\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# pragma: full coverage\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\uvicorn\\server.py:67\u001b[39m, in \u001b[36mServer.run\u001b[39m\u001b[34m(self, sockets)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket.socket] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m=\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loop_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\asyncio\\runners.py:190\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    186\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    # Run server\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856bf47-041d-40e6-828f-09225faf1e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
